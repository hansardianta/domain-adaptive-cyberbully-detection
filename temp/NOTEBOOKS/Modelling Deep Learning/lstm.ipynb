{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c5b8b",
   "metadata": {},
   "source": [
    "# INFORMASI\n",
    "### LSTM\n",
    "### Fine Tuning pada data Twitter, pergunakan weights nya lalu fine-tune kembali pada data YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a334a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Konfigurasi ---\n",
    "MAX_NB_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# --- Load Data Twitter ---\n",
    "df_twitter = pd.read_csv('final_data_twitter.csv')\n",
    "df_twitter = df_twitter.dropna(subset=['clean_text_ML_2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669282f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tokenisasi (Fit pada data Twitter) ---\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(df_twitter['clean_text_ML_2'].values)\n",
    "\n",
    "X_tw = tokenizer.texts_to_sequences(df_twitter['clean_text_ML_2'].values)\n",
    "X_tw = pad_sequences(X_tw, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_tw = df_twitter['cyberbullying'].values\n",
    "\n",
    "# Split Data Twitter\n",
    "X_temp_tw, X_test_tw, y_temp_tw, y_test_tw = train_test_split(X_tw, y_tw, test_size=0.2, random_state=42)\n",
    "X_train_tw, X_val_tw, y_train_tw, y_val_tw = train_test_split(X_temp_tw, y_temp_tw, test_size=1/8, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29b7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, 'float32'))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, 'float32'))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), 'float32'))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall = tp / (tp + fn + 1e-7)\n",
    "\n",
    "    return 2 * precision * recall / (precision + recall + 1e-7)\n",
    "\n",
    "\n",
    "# --- Membangun Model LSTM ---\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',\n",
    "        Precision(name=\"precision\"),\n",
    "        Recall(name=\"recall\"),\n",
    "        f1_metric\n",
    "        ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecea6ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training Model pada Data Twitter...\n",
      "Epoch 1/8\n",
      "143/143 [==============================] - 28s 180ms/step - loss: 0.5281 - accuracy: 0.7233 - precision: 0.7758 - recall: 0.4868 - f1_metric: 0.5158 - val_loss: 0.4098 - val_accuracy: 0.8163 - val_precision: 0.7883 - val_recall: 0.7665 - val_f1_metric: 0.7699\n",
      "Epoch 2/8\n",
      "143/143 [==============================] - 26s 181ms/step - loss: 0.3215 - accuracy: 0.8587 - precision: 0.8352 - recall: 0.8300 - f1_metric: 0.8297 - val_loss: 0.4077 - val_accuracy: 0.8255 - val_precision: 0.8365 - val_recall: 0.7243 - val_f1_metric: 0.7744\n",
      "Epoch 3/8\n",
      "143/143 [==============================] - 25s 176ms/step - loss: 0.2552 - accuracy: 0.8942 - precision: 0.8765 - recall: 0.8731 - f1_metric: 0.8738 - val_loss: 0.4464 - val_accuracy: 0.8186 - val_precision: 0.8438 - val_recall: 0.6949 - val_f1_metric: 0.7584\n",
      "Epoch 4/8\n",
      "143/143 [==============================] - 28s 198ms/step - loss: 0.2115 - accuracy: 0.9138 - precision: 0.8982 - recall: 0.8980 - f1_metric: 0.8976 - val_loss: 0.4599 - val_accuracy: 0.8194 - val_precision: 0.7899 - val_recall: 0.7739 - val_f1_metric: 0.7788\n",
      "Epoch 5/8\n",
      "143/143 [==============================] - 60s 418ms/step - loss: 0.1794 - accuracy: 0.9287 - precision: 0.9101 - recall: 0.9226 - f1_metric: 0.9136 - val_loss: 0.4877 - val_accuracy: 0.8171 - val_precision: 0.8060 - val_recall: 0.7408 - val_f1_metric: 0.7691\n",
      "Epoch 6/8\n",
      "143/143 [==============================] - 44s 306ms/step - loss: 0.1507 - accuracy: 0.9416 - precision: 0.9294 - recall: 0.9328 - f1_metric: 0.9292 - val_loss: 0.5449 - val_accuracy: 0.8194 - val_precision: 0.8047 - val_recall: 0.7500 - val_f1_metric: 0.7744\n",
      "Epoch 7/8\n",
      "143/143 [==============================] - 25s 174ms/step - loss: 0.1320 - accuracy: 0.9511 - precision: 0.9408 - recall: 0.9439 - f1_metric: 0.9418 - val_loss: 0.5986 - val_accuracy: 0.8101 - val_precision: 0.7818 - val_recall: 0.7574 - val_f1_metric: 0.7684\n",
      "Epoch 8/8\n",
      "143/143 [==============================] - 25s 176ms/step - loss: 0.1097 - accuracy: 0.9578 - precision: 0.9483 - recall: 0.9522 - f1_metric: 0.9498 - val_loss: 0.6535 - val_accuracy: 0.8063 - val_precision: 0.7724 - val_recall: 0.7610 - val_f1_metric: 0.7658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ac0bd9bc10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model pada Twitter\n",
    "model_tw = create_model()\n",
    "print(\"Training Model pada Data Twitter...\")\n",
    "model_tw.fit(X_train_tw, y_train_tw, epochs=8, batch_size=64, validation_data=(X_val_tw, y_val_tw), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a5b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 2s 19ms/step - loss: 0.6305 - accuracy: 0.7948 - precision: 0.7582 - recall: 0.7582 - f1_metric: 0.7530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6305282115936279,\n",
       " 0.794773280620575,\n",
       " 0.758152186870575,\n",
       " 0.758152186870575,\n",
       " 0.7529876232147217]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tw.evaluate(X_test_tw, y_test_tw, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0fe302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot model Twitter berhasil disimpan.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Simpan Weights ---\n",
    "model_tw.save_weights('twitter_weights.h5')\n",
    "print(\"Bobot model Twitter berhasil disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0afcd198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Data YouTube ---\n",
    "df_yt = pd.read_csv('final_data_yt.csv')\n",
    "df_yt = df_yt.dropna(subset=['clean_text_ML_2'])\n",
    "\n",
    "# --- Preprocessing YouTube (Pakai Tokenizer Twitter) ---\n",
    "X_yt = tokenizer.texts_to_sequences(df_yt['clean_text_ML_2'].values)\n",
    "X_yt = pad_sequences(X_yt, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_yt = df_yt['cyberbullying'].values\n",
    "\n",
    "# Split Data YouTube\n",
    "X_temp_yt, X_test_yt, y_temp_yt, y_test_yt = train_test_split(X_yt, y_yt, test_size=0.2, random_state=42)\n",
    "X_train_yt, X_val_yt, y_train_yt, y_val_yt = train_test_split(X_temp_yt, y_temp_yt, test_size=1/8, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd48e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.50266695]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load Model & Weights ---\n",
    "model_finetune = create_model()\n",
    "\n",
    "# Trik: Jalankan dummy input agar struktur model terbangun sebelum load weights\n",
    "dummy_input = np.zeros((1, MAX_SEQUENCE_LENGTH))\n",
    "model_finetune(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba9e7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bobot Twitter dimuat. Mulai Fine-tuning pada Data YouTube...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load bobot dari Twitter\n",
    "model_finetune.load_weights('twitter_weights.h5')\n",
    "print(\"\\nBobot Twitter dimuat. Mulai Fine-tuning pada Data YouTube...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8780cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "8/8 [==============================] - 3s 241ms/step - loss: 1.2161 - accuracy: 0.6088 - precision: 0.5053 - recall: 0.2682 - f1_metric: 0.3869 - val_loss: 0.8619 - val_accuracy: 0.6769 - val_precision: 0.5455 - val_recall: 0.5217 - val_f1_metric: 0.2667\n",
      "Epoch 2/8\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.8267 - accuracy: 0.6462 - precision: 0.5608 - recall: 0.4637 - f1_metric: 0.4492 - val_loss: 0.7671 - val_accuracy: 0.6615 - val_precision: 0.5185 - val_recall: 0.6087 - val_f1_metric: 0.2800\n",
      "Epoch 3/8\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 0.6756 - accuracy: 0.6725 - precision: 0.5962 - recall: 0.5196 - f1_metric: 0.5678 - val_loss: 0.7170 - val_accuracy: 0.6462 - val_precision: 0.5000 - val_recall: 0.5217 - val_f1_metric: 0.2553\n",
      "Epoch 4/8\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.6082 - accuracy: 0.6945 - precision: 0.6220 - recall: 0.5698 - f1_metric: 0.5778 - val_loss: 0.6872 - val_accuracy: 0.6923 - val_precision: 0.5600 - val_recall: 0.6087 - val_f1_metric: 0.2917\n",
      "Epoch 5/8\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.5348 - accuracy: 0.7473 - precision: 0.6951 - recall: 0.6369 - f1_metric: 0.6764 - val_loss: 0.6651 - val_accuracy: 0.6923 - val_precision: 0.5600 - val_recall: 0.6087 - val_f1_metric: 0.2917\n",
      "Epoch 6/8\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.4849 - accuracy: 0.7736 - precision: 0.7111 - recall: 0.7151 - f1_metric: 0.6795 - val_loss: 0.6525 - val_accuracy: 0.6923 - val_precision: 0.5600 - val_recall: 0.6087 - val_f1_metric: 0.2917\n",
      "Epoch 7/8\n",
      "8/8 [==============================] - 1s 169ms/step - loss: 0.4488 - accuracy: 0.8110 - precision: 0.8000 - recall: 0.6927 - f1_metric: 0.7488 - val_loss: 0.6396 - val_accuracy: 0.6769 - val_precision: 0.5500 - val_recall: 0.4783 - val_f1_metric: 0.2558\n",
      "Epoch 8/8\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 0.4112 - accuracy: 0.8132 - precision: 0.8013 - recall: 0.6983 - f1_metric: 0.7754 - val_loss: 0.6642 - val_accuracy: 0.6923 - val_precision: 0.5600 - val_recall: 0.6087 - val_f1_metric: 0.2917\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',      # metric yang dipantau\n",
    "    patience=3,              # stop jika 2 epoch berturut-turut tidak membaik\n",
    "    restore_best_weights=True # kembalikan weight terbaik (recommended)\n",
    ")\n",
    "\n",
    "# --- Fine-Tuning ---\n",
    "# Kita lanjutkan training dengan data YouTube\n",
    "history_yt = model_finetune.fit(X_train_yt, y_train_yt, epochs=8, batch_size=64, validation_data=(X_val_yt, y_val_yt), callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22e018e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7284 - accuracy: 0.6615 - precision: 0.4878 - recall: 0.4651 - f1_metric: 0.3655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7284189462661743,\n",
       " 0.6615384817123413,\n",
       " 0.4878048896789551,\n",
       " 0.4651162922382355,\n",
       " 0.36546745896339417]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_finetune.evaluate(X_test_yt, y_test_yt, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
