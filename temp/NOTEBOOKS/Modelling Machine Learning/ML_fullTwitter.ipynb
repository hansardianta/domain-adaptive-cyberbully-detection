{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f360366",
   "metadata": {},
   "source": [
    "# INFORMASI\n",
    "### Metode Machine Learning\n",
    "### Ditrain hanya pada data Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb962c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde97cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.read_csv('../data/final_data_twitter.csv')\n",
    "df_yt = pd.read_csv('../data/final_data_yt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e5cedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cyberbullying</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_text_bert</th>\n",
       "      <th>clean_text_ML</th>\n",
       "      <th>clean_text_ML_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- di saat semua cowok berusaha melacak perhati...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>di saat semua cowok berusaha melacak perhatian...</td>\n",
       "      <td>semua cowok berusaha melacak perhatian gue kam...</td>\n",
       "      <td>semua usaha lacak hati gue lantas remehkan hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT PENGGUNA: PENGGUNA siapa yang telat memberi...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>siapa yang telat memberi tau kamu?edan sarap g...</td>\n",
       "      <td>siapa telat memberi tau kamu edan sarap gue be...</td>\n",
       "      <td>telat beri tau edan sarap gue gaul cigax jifla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41. Kadang aku berpikir, kenapa aku tetap perc...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>41. Kadang aku berpikir kenapa aku tetap perca...</td>\n",
       "      <td>kadang aku berpikir aku tetap percaya tuhan pa...</td>\n",
       "      <td>kadang pikir tetap percaya tuhan padahal selal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENGGUNA PENGGUNA AKU ITU AKU\\dan\\ku TAU MATAM...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>AKU ITU AKU dan ku TAU MATAMU SIPIT TAPI DILIH...</td>\n",
       "      <td>aku aku ku tau matamu sipit dilihat mana aku</td>\n",
       "      <td>tau mata kamu sipit lihat mana aku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENGGUNA PENGGUNA Kaum cebong kafir sudah keli...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Kaum cebong kafir sudah kelihatan dongoknya da...</td>\n",
       "      <td>kaum cebong kafir kelihatan dongoknya awal tam...</td>\n",
       "      <td>cebong kafir lihat dongok nya awal tambah dung...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cyberbullying  length  \\\n",
       "0  - di saat semua cowok berusaha melacak perhati...              1      26   \n",
       "1  RT PENGGUNA: PENGGUNA siapa yang telat memberi...              0      21   \n",
       "2  41. Kadang aku berpikir, kenapa aku tetap perc...              0      38   \n",
       "3  PENGGUNA PENGGUNA AKU ITU AKU\\dan\\ku TAU MATAM...              0      14   \n",
       "4  PENGGUNA PENGGUNA Kaum cebong kafir sudah keli...              1      14   \n",
       "\n",
       "                                     clean_text_bert  \\\n",
       "0  di saat semua cowok berusaha melacak perhatian...   \n",
       "1  siapa yang telat memberi tau kamu?edan sarap g...   \n",
       "2  41. Kadang aku berpikir kenapa aku tetap perca...   \n",
       "3  AKU ITU AKU dan ku TAU MATAMU SIPIT TAPI DILIH...   \n",
       "4  Kaum cebong kafir sudah kelihatan dongoknya da...   \n",
       "\n",
       "                                       clean_text_ML  \\\n",
       "0  semua cowok berusaha melacak perhatian gue kam...   \n",
       "1  siapa telat memberi tau kamu edan sarap gue be...   \n",
       "2  kadang aku berpikir aku tetap percaya tuhan pa...   \n",
       "3       aku aku ku tau matamu sipit dilihat mana aku   \n",
       "4  kaum cebong kafir kelihatan dongoknya awal tam...   \n",
       "\n",
       "                                     clean_text_ML_2  \n",
       "0  semua usaha lacak hati gue lantas remehkan hat...  \n",
       "1  telat beri tau edan sarap gue gaul cigax jifla...  \n",
       "2  kadang pikir tetap percaya tuhan padahal selal...  \n",
       "3                 tau mata kamu sipit lihat mana aku  \n",
       "4  cebong kafir lihat dongok nya awal tambah dung...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e23296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cyberbullying</th>\n",
       "      <th>clean_text_bert</th>\n",
       "      <th>clean_text_ML</th>\n",
       "      <th>clean_text_ML_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kalau cowok sudah sakit hati dan kecewa memang...</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau cowok sudah sakit hati dan kecewa memang...</td>\n",
       "      <td>kalau cowok sakit hati kecewa memang kayak mbak</td>\n",
       "      <td>kalau cowok sakit hati kecewa memang kayak mbak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Om ded kasih panggung ke cewek problematik bia...</td>\n",
       "      <td>1</td>\n",
       "      <td>Om ded kasih panggung ke cewek problematik bia...</td>\n",
       "      <td>om ded kasih panggung cewek problematik biaya ...</td>\n",
       "      <td>om ded kasih panggung cewek problematik biaya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>om ded?? apa are kamu doing !!!!!!!!!!!!!</td>\n",
       "      <td>0</td>\n",
       "      <td>om ded? apa are kamu doing !</td>\n",
       "      <td>om ded apa are kamu doing</td>\n",
       "      <td>om ded apa are kamu doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ya Allah,jauhkan anak anak kita dari pergaulan...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ya Allah jauhkan anak anak kita dari pergaulan...</td>\n",
       "      <td>allah jauhkan anak anak pergaulan bebas dunia ...</td>\n",
       "      <td>jauh anak anak gaul bebas dunia malam hubung s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gue kira pintar people, tetapi hal kayak begin...</td>\n",
       "      <td>0</td>\n",
       "      <td>gue kira pintar people tetapi hal kayak begini...</td>\n",
       "      <td>gue kira pintar people kayak begini angkat pod...</td>\n",
       "      <td>gue kira pintar people kayak begini angkat pod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cyberbullying  \\\n",
       "0  Kalau cowok sudah sakit hati dan kecewa memang...              0   \n",
       "1  Om ded kasih panggung ke cewek problematik bia...              1   \n",
       "2          om ded?? apa are kamu doing !!!!!!!!!!!!!              0   \n",
       "3  Ya Allah,jauhkan anak anak kita dari pergaulan...              0   \n",
       "4  gue kira pintar people, tetapi hal kayak begin...              0   \n",
       "\n",
       "                                     clean_text_bert  \\\n",
       "0  Kalau cowok sudah sakit hati dan kecewa memang...   \n",
       "1  Om ded kasih panggung ke cewek problematik bia...   \n",
       "2                       om ded? apa are kamu doing !   \n",
       "3  Ya Allah jauhkan anak anak kita dari pergaulan...   \n",
       "4  gue kira pintar people tetapi hal kayak begini...   \n",
       "\n",
       "                                       clean_text_ML  \\\n",
       "0    kalau cowok sakit hati kecewa memang kayak mbak   \n",
       "1  om ded kasih panggung cewek problematik biaya ...   \n",
       "2                          om ded apa are kamu doing   \n",
       "3  allah jauhkan anak anak pergaulan bebas dunia ...   \n",
       "4  gue kira pintar people kayak begini angkat pod...   \n",
       "\n",
       "                                     clean_text_ML_2  \n",
       "0    kalau cowok sakit hati kecewa memang kayak mbak  \n",
       "1  om ded kasih panggung cewek problematik biaya ...  \n",
       "2                          om ded apa are kamu doing  \n",
       "3  jauh anak anak gaul bebas dunia malam hubung s...  \n",
       "4  gue kira pintar people kayak begini angkat pod...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d289b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13017 entries, 0 to 13016\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text             13017 non-null  object\n",
      " 1   cyberbullying    13017 non-null  int64 \n",
      " 2   length           13017 non-null  int64 \n",
      " 3   clean_text_bert  13006 non-null  object\n",
      " 4   clean_text_ML    13006 non-null  object\n",
      " 5   clean_text_ML_2  13006 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 610.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493a24d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 650 entries, 0 to 649\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text             650 non-null    object\n",
      " 1   cyberbullying    650 non-null    int64 \n",
      " 2   clean_text_bert  650 non-null    object\n",
      " 3   clean_text_ML    650 non-null    object\n",
      " 4   clean_text_ML_2  650 non-null    object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 25.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_yt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4863e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = df_twitter.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03030592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13005 entries, 0 to 13016\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   text             13005 non-null  object\n",
      " 1   cyberbullying    13005 non-null  int64 \n",
      " 2   length           13005 non-null  int64 \n",
      " 3   clean_text_bert  13005 non-null  object\n",
      " 4   clean_text_ML    13005 non-null  object\n",
      " 5   clean_text_ML_2  13005 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 711.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f096b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df_twitter['clean_text_ML_2']\n",
    "y = df_twitter['cyberbullying']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.2, # 20% buat val dan test\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5, # 10% val, 10% test\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26549d18",
   "metadata": {},
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f55dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def sentence_vector(text, embedding_model, dim=100):\n",
    "    words = text.split()\n",
    "    vectors = []\n",
    "    for w in words:\n",
    "        if w in embedding_model:\n",
    "            vectors.append(embedding_model[w])\n",
    "    \n",
    "    # Jika tidak ada satupun kata punya embedding -> return zero vector\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    \n",
    "    # Rata-rata embedding\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846fc32",
   "metadata": {},
   "source": [
    "Misalkan kalimat 'Politik Indonesia hancur', lalu pakai embedding dimensi 300 maka tiap kata punya vektor 300 dimensi kemudian dilakukan averaging:\n",
    "\n",
    "$$\n",
    "\\mathbf{s} \\;=\\; \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{w}_i\n",
    "$$\n",
    "\n",
    "Dengan teknik ini, setiap kalimat direpresentasikan sebagai sebuah vektor berdimensi 300. Kelebihannya adalah metode ini sederhana dan mampu menyamakan dimensi antar-kalimat. Namun, kelemahannya adalah informasi dari kata-kata yang penting dapat melemah karena proses perataan (averaging) membuat kontribusi setiap kata menjadi relatif sama.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d336994",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f63bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    max_df=0.9,\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf   = tfidf.transform(X_val)\n",
    "X_test_tfidf  = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c50c9",
   "metadata": {},
   "source": [
    "#### GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2425166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/gensim/models/keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "def load_glove(glove_file, dim=50):\n",
    "    glove_model = KeyedVectors(vector_size=dim)\n",
    "    \n",
    "    with open(glove_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            glove_model.add_vector(word, vector)\n",
    "    \n",
    "    return glove_model\n",
    "\n",
    "# Load model\n",
    "glove_vectors = load_glove(\"../model pretrained/glove/glove_50dim_wiki.id.case.text.txt\", dim=50)\n",
    "\n",
    "X_train_glove = np.vstack([sentence_vector(s, glove_vectors, dim=50) for s in X_train])\n",
    "X_val_glove   = np.vstack([sentence_vector(s, glove_vectors, dim=50) for s in X_val])\n",
    "X_test_glove  = np.vstack([sentence_vector(s, glove_vectors, dim=50) for s in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca0257",
   "metadata": {},
   "source": [
    "#### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6617811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "fasttext_model = gensim.models.fasttext.load_facebook_model(\"../model pretrained/fasttext/cc.id.300.bin\") # Dilatih dari data Common Crawl\n",
    "fasttext_vectors = fasttext_model.wv\n",
    "fasttext_dim = fasttext_vectors.vector_size\n",
    "\n",
    "\n",
    "X_train_fasttext = np.vstack([sentence_vector(text, fasttext_vectors, dim=fasttext_dim) for text in X_train])\n",
    "X_val_fasttext = np.vstack([sentence_vector(text, fasttext_vectors, dim=fasttext_dim) for text in X_val])\n",
    "X_test_fasttext = np.vstack([sentence_vector(text, fasttext_vectors, dim=fasttext_dim) for text in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e2ca0",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb56475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_wiki = Word2Vec.load(\"../model pretrained/word2vec/idwiki_word2vec_100/idwiki_word2vec_100.model\")\n",
    "w2v_vectors = w2v_wiki.wv\n",
    "w2v_dim = w2v_vectors.vector_size\n",
    "\n",
    "X_train_w2v = np.vstack([sentence_vector(text, w2v_vectors, dim=w2v_dim) for text in X_train])\n",
    "X_val_w2v = np.vstack([sentence_vector(text, w2v_vectors, dim=w2v_dim) for text in X_val])\n",
    "X_test_w2v = np.vstack([sentence_vector(text, w2v_vectors, dim=w2v_dim) for text in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad51604",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eae993",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "568e1281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:08:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:08:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:08:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:08:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Text Representation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.832462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.821250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.765531</td>\n",
       "      <td>0.694545</td>\n",
       "      <td>0.772280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.764615</td>\n",
       "      <td>0.772321</td>\n",
       "      <td>0.629091</td>\n",
       "      <td>0.751188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.709231</td>\n",
       "      <td>0.670635</td>\n",
       "      <td>0.614545</td>\n",
       "      <td>0.698432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.709231</td>\n",
       "      <td>0.676230</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.696920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.701538</td>\n",
       "      <td>0.668050</td>\n",
       "      <td>0.585455</td>\n",
       "      <td>0.688291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.651538</td>\n",
       "      <td>0.576378</td>\n",
       "      <td>0.665455</td>\n",
       "      <td>0.648790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.659847</td>\n",
       "      <td>0.469091</td>\n",
       "      <td>0.646087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.623846</td>\n",
       "      <td>0.533776</td>\n",
       "      <td>0.876364</td>\n",
       "      <td>0.618563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.510883</td>\n",
       "      <td>0.725455</td>\n",
       "      <td>0.589767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.462446</td>\n",
       "      <td>0.783636</td>\n",
       "      <td>0.513542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model         Text Representation  Accuracy  Precision    Recall  \\\n",
       "0           SVM                      TF-IDF  0.838462   0.837302  0.767273   \n",
       "1       XGBoost                      TF-IDF  0.830769   0.866667  0.709091   \n",
       "2       XGBoost  FastText CC (Common Crawl)  0.780769   0.765531  0.694545   \n",
       "3           SVM  FastText CC (Common Crawl)  0.764615   0.772321  0.629091   \n",
       "4       XGBoost          Word2Vec Wikipedia  0.709231   0.670635  0.614545   \n",
       "5       XGBoost             Glove Wikipedia  0.709231   0.676230  0.600000   \n",
       "6           SVM          Word2Vec Wikipedia  0.701538   0.668050  0.585455   \n",
       "7   Naive Bayes             Glove Wikipedia  0.651538   0.576378  0.665455   \n",
       "8           SVM             Glove Wikipedia  0.673077   0.659847  0.469091   \n",
       "9   Naive Bayes                      TF-IDF  0.623846   0.533776  0.876364   \n",
       "10  Naive Bayes          Word2Vec Wikipedia  0.590000   0.510883  0.725455   \n",
       "11  Naive Bayes  FastText CC (Common Crawl)  0.523077   0.462446  0.783636   \n",
       "\n",
       "    F1 Macro  \n",
       "0   0.832462  \n",
       "1   0.821250  \n",
       "2   0.772280  \n",
       "3   0.751188  \n",
       "4   0.698432  \n",
       "5   0.696920  \n",
       "6   0.688291  \n",
       "7   0.648790  \n",
       "8   0.646087  \n",
       "9   0.618563  \n",
       "10  0.589767  \n",
       "11  0.513542  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Representasi teks\n",
    "representations = {\n",
    "    'TF-IDF': (X_train_tfidf.toarray(), X_val_tfidf.toarray()),\n",
    "    'Glove Wikipedia': (X_train_glove, X_val_glove),\n",
    "    'FastText CC (Common Crawl)': (X_train_fasttext, X_val_fasttext),\n",
    "    'Word2Vec Wikipedia': (X_train_w2v, X_val_w2v)  \n",
    "}\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for rep_name, (X_tr, X_vl) in representations.items():\n",
    "        model.fit(X_tr, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_vl)\n",
    "        \n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Text Representation': rep_name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Macro': f1\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='F1 Macro', ascending=False)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9783d63d",
   "metadata": {},
   "source": [
    "### Handle Imbalance (Parameter Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e7dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:10:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:10:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:10:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:10:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Text Representation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.828462</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.825222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.829231</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>0.752727</td>\n",
       "      <td>0.822673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.793846</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.729091</td>\n",
       "      <td>0.787185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.722420</td>\n",
       "      <td>0.738182</td>\n",
       "      <td>0.764301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.704615</td>\n",
       "      <td>0.652015</td>\n",
       "      <td>0.647273</td>\n",
       "      <td>0.697158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.696154</td>\n",
       "      <td>0.625608</td>\n",
       "      <td>0.701818</td>\n",
       "      <td>0.692940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.694615</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.686191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.678462</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.675009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.651538</td>\n",
       "      <td>0.576378</td>\n",
       "      <td>0.665455</td>\n",
       "      <td>0.648790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.623846</td>\n",
       "      <td>0.533776</td>\n",
       "      <td>0.876364</td>\n",
       "      <td>0.618563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.510883</td>\n",
       "      <td>0.725455</td>\n",
       "      <td>0.589767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.462446</td>\n",
       "      <td>0.783636</td>\n",
       "      <td>0.513542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model         Text Representation  Accuracy  Precision    Recall  \\\n",
       "0           SVM                      TF-IDF  0.828462   0.785340  0.818182   \n",
       "1       XGBoost                      TF-IDF  0.829231   0.828000  0.752727   \n",
       "2       XGBoost  FastText CC (Common Crawl)  0.793846   0.771154  0.729091   \n",
       "3           SVM  FastText CC (Common Crawl)  0.769231   0.722420  0.738182   \n",
       "4       XGBoost          Word2Vec Wikipedia  0.704615   0.652015  0.647273   \n",
       "5           SVM          Word2Vec Wikipedia  0.696154   0.625608  0.701818   \n",
       "6       XGBoost             Glove Wikipedia  0.694615   0.642458  0.627273   \n",
       "7           SVM             Glove Wikipedia  0.678462   0.607143  0.680000   \n",
       "8   Naive Bayes             Glove Wikipedia  0.651538   0.576378  0.665455   \n",
       "9   Naive Bayes                      TF-IDF  0.623846   0.533776  0.876364   \n",
       "10  Naive Bayes          Word2Vec Wikipedia  0.590000   0.510883  0.725455   \n",
       "11  Naive Bayes  FastText CC (Common Crawl)  0.523077   0.462446  0.783636   \n",
       "\n",
       "    F1 Macro  \n",
       "0   0.825222  \n",
       "1   0.822673  \n",
       "2   0.787185  \n",
       "3   0.764301  \n",
       "4   0.697158  \n",
       "5   0.692940  \n",
       "6   0.686191  \n",
       "7   0.675009  \n",
       "8   0.648790  \n",
       "9   0.618563  \n",
       "10  0.589767  \n",
       "11  0.513542  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "models_balanced = {\n",
    "    'SVM': SVC(kernel='linear', class_weight='balanced', random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "results_class_weight = []\n",
    "\n",
    "for model_name, model in models_balanced.items():\n",
    "    for rep_name, (X_tr, X_vl) in representations.items():\n",
    "        \n",
    "        model.fit(X_tr, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_vl)\n",
    "        \n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_val, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "        \n",
    "        results_class_weight.append({\n",
    "            'Model': model_name,\n",
    "            'Text Representation': rep_name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Macro': f1\n",
    "        })\n",
    "\n",
    "results_class_weight_df = pd.DataFrame(results_class_weight)\n",
    "results_class_weight_df = results_class_weight_df.sort_values(by='F1 Macro', ascending=False)\n",
    "results_class_weight_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results_class_weight_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd225d",
   "metadata": {},
   "source": [
    "# Testing dan Hasil "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ebae1",
   "metadata": {},
   "source": [
    "##### Data Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a7c2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_test_twitter = {\n",
    "    'TF-IDF': X_test_tfidf.toarray(),\n",
    "    'Glove Wikipedia': X_test_glove,\n",
    "    'FastText CC (Common Crawl)': X_test_fasttext,\n",
    "    'Word2Vec Wikipedia': X_test_w2v  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd75d8",
   "metadata": {},
   "source": [
    "##### Data Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d222d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_yt = df_yt['clean_text_ML_2']\n",
    "y_test_yt = df_yt['cyberbullying']\n",
    "\n",
    "X_test_yt_tfidf = tfidf.transform(X_test_yt).toarray()\n",
    "\n",
    "X_test_yt_glove = np.vstack([sentence_vector(text, glove_vectors, dim=50) for text in X_test_yt])\n",
    "\n",
    "X_test_yt_fasttext = np.vstack([sentence_vector(text, fasttext_vectors, dim=fasttext_dim) for text in X_test_yt])\n",
    "\n",
    "X_test_yt_w2v = np.vstack([sentence_vector(text, w2v_vectors, dim=w2v_dim) for text in X_test_yt])\n",
    "\n",
    "representations_test_yt = {\n",
    "    'TF-IDF': X_test_yt_tfidf,\n",
    "    'Glove Wikipedia': X_test_yt_glove,\n",
    "    'FastText CC (Common Crawl)': X_test_yt_fasttext,\n",
    "    'Word2Vec Wikipedia': X_test_yt_w2v  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353d1b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:18:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:18:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:18:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/jowillg/anaconda3/envs/pytorch_DL/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [14:18:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "results_twitter = []\n",
    "results_youtube = []\n",
    "\n",
    "for model_name, model in models_balanced.items():\n",
    "    for rep_name, (X_tr, X_val_rep) in representations.items():\n",
    "        \n",
    "        # TRAIN ONLY ON TWITTER\n",
    "        model.fit(X_tr, y_train) \n",
    "        \n",
    "        # TEST TWITTER\n",
    "        X_test_twitter_rep = representations_test_twitter[rep_name]\n",
    "        y_pred_test_tw = model.predict(X_test_twitter_rep)\n",
    "        \n",
    "        results_twitter.append({\n",
    "            'Model': model_name,\n",
    "            'Representation': rep_name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred_test_tw),\n",
    "            'Precision': precision_score(y_test, y_pred_test_tw, zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred_test_tw, zero_division=0),\n",
    "            'F1': f1_score(y_test, y_pred_test_tw, average='macro', zero_division=0)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        # TEST YOUTUBE\n",
    "        X_test_yt_rep = representations_test_yt[rep_name]\n",
    "        y_pred_test_yt = model.predict(X_test_yt_rep)\n",
    "        \n",
    "        results_youtube.append({\n",
    "            'Model': model_name,\n",
    "            'Representation': rep_name,\n",
    "            'Accuracy': accuracy_score(y_test_yt, y_pred_test_yt),\n",
    "            'Precision': precision_score(y_test_yt, y_pred_test_yt, zero_division=0),\n",
    "            'Recall': recall_score(y_test_yt, y_pred_test_yt, zero_division=0),\n",
    "            'F1': f1_score(y_test_yt, y_pred_test_yt, average='macro', zero_division=0)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b182929",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_twitter = pd.DataFrame(results_twitter).sort_values(by='F1', ascending=False).reset_index(drop=True)\n",
    "results_youtube = pd.DataFrame(results_youtube).sort_values(by='F1', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856b4da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Twitter: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.837048</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.832727</td>\n",
       "      <td>0.834115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.817832</td>\n",
       "      <td>0.806262</td>\n",
       "      <td>0.749091</td>\n",
       "      <td>0.811415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.796311</td>\n",
       "      <td>0.772467</td>\n",
       "      <td>0.734545</td>\n",
       "      <td>0.789856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.775557</td>\n",
       "      <td>0.718644</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.772067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.744812</td>\n",
       "      <td>0.702602</td>\n",
       "      <td>0.687273</td>\n",
       "      <td>0.737783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.707917</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.706146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.704074</td>\n",
       "      <td>0.650273</td>\n",
       "      <td>0.649091</td>\n",
       "      <td>0.696764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.594551</td>\n",
       "      <td>0.674545</td>\n",
       "      <td>0.664753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.655650</td>\n",
       "      <td>0.579937</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.653032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.643351</td>\n",
       "      <td>0.547884</td>\n",
       "      <td>0.894545</td>\n",
       "      <td>0.638739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.625673</td>\n",
       "      <td>0.541833</td>\n",
       "      <td>0.741818</td>\n",
       "      <td>0.625672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.534204</td>\n",
       "      <td>0.470021</td>\n",
       "      <td>0.798182</td>\n",
       "      <td>0.524802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model              Representation  Accuracy  Precision    Recall  \\\n",
       "0           SVM                      TF-IDF  0.837048   0.792388  0.832727   \n",
       "1       XGBoost                      TF-IDF  0.817832   0.806262  0.749091   \n",
       "2       XGBoost  FastText CC (Common Crawl)  0.796311   0.772467  0.734545   \n",
       "3           SVM  FastText CC (Common Crawl)  0.775557   0.718644  0.770909   \n",
       "4       XGBoost          Word2Vec Wikipedia  0.744812   0.702602  0.687273   \n",
       "5           SVM          Word2Vec Wikipedia  0.707917   0.630769  0.745455   \n",
       "6       XGBoost             Glove Wikipedia  0.704074   0.650273  0.649091   \n",
       "7   Naive Bayes             Glove Wikipedia  0.667948   0.594551  0.674545   \n",
       "8           SVM             Glove Wikipedia  0.655650   0.579937  0.672727   \n",
       "9   Naive Bayes                      TF-IDF  0.643351   0.547884  0.894545   \n",
       "10  Naive Bayes          Word2Vec Wikipedia  0.625673   0.541833  0.741818   \n",
       "11  Naive Bayes  FastText CC (Common Crawl)  0.534204   0.470021  0.798182   \n",
       "\n",
       "          F1  \n",
       "0   0.834115  \n",
       "1   0.811415  \n",
       "2   0.789856  \n",
       "3   0.772067  \n",
       "4   0.737783  \n",
       "5   0.706146  \n",
       "6   0.696764  \n",
       "7   0.664753  \n",
       "8   0.653032  \n",
       "9   0.638739  \n",
       "10  0.625672  \n",
       "11  0.524802  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil Youtube:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.302041</td>\n",
       "      <td>0.547349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.621538</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.536812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.302041</td>\n",
       "      <td>0.520482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.587692</td>\n",
       "      <td>0.427673</td>\n",
       "      <td>0.277551</td>\n",
       "      <td>0.518763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>0.253061</td>\n",
       "      <td>0.508354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.563077</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.269388</td>\n",
       "      <td>0.498020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.636923</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.138776</td>\n",
       "      <td>0.493368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Glove Wikipedia</td>\n",
       "      <td>0.567692</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.216327</td>\n",
       "      <td>0.483063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.175510</td>\n",
       "      <td>0.482886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Word2Vec Wikipedia</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.344720</td>\n",
       "      <td>0.453061</td>\n",
       "      <td>0.460433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.435385</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.636735</td>\n",
       "      <td>0.434258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>FastText CC (Common Crawl)</td>\n",
       "      <td>0.424615</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.424267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model              Representation  Accuracy  Precision    Recall  \\\n",
       "0           SVM                      TF-IDF  0.615385   0.483660  0.302041   \n",
       "1           SVM  FastText CC (Common Crawl)  0.621538   0.496063  0.257143   \n",
       "2           SVM          Word2Vec Wikipedia  0.580000   0.420455  0.302041   \n",
       "3           SVM             Glove Wikipedia  0.587692   0.427673  0.277551   \n",
       "4       XGBoost          Word2Vec Wikipedia  0.584615   0.416107  0.253061   \n",
       "5   Naive Bayes             Glove Wikipedia  0.563077   0.385965  0.269388   \n",
       "6       XGBoost                      TF-IDF  0.636923   0.576271  0.138776   \n",
       "7       XGBoost             Glove Wikipedia  0.567692   0.373239  0.216327   \n",
       "8       XGBoost  FastText CC (Common Crawl)  0.592308   0.405660  0.175510   \n",
       "9   Naive Bayes          Word2Vec Wikipedia  0.469231   0.344720  0.453061   \n",
       "10  Naive Bayes                      TF-IDF  0.435385   0.359447  0.636735   \n",
       "11  Naive Bayes  FastText CC (Common Crawl)  0.424615   0.334190  0.530612   \n",
       "\n",
       "          F1  \n",
       "0   0.547349  \n",
       "1   0.536812  \n",
       "2   0.520482  \n",
       "3   0.518763  \n",
       "4   0.508354  \n",
       "5   0.498020  \n",
       "6   0.493368  \n",
       "7   0.483063  \n",
       "8   0.482886  \n",
       "9   0.460433  \n",
       "10  0.434258  \n",
       "11  0.424267  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Hasil Twitter: \")\n",
    "display(results_twitter)\n",
    "print(\"\\nHasil Youtube:\")\n",
    "display(results_youtube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379eeb9e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
