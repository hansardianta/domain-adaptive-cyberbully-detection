{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace40446",
   "metadata": {},
   "source": [
    "# INFORMASI\n",
    "### Bi-LSTM\n",
    "### Fine Tuning pada data Twitter, pergunakan weights nya lalu fine-tune kembali pada data YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24728121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Konfigurasi ---\n",
    "MAX_NB_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# --- Load Data Twitter ---\n",
    "df_twitter = pd.read_csv('final_data_twitter.csv')\n",
    "df_twitter = df_twitter.dropna(subset=['clean_text_ML_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44cc870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tokenisasi (Fit pada data Twitter) ---\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(df_twitter['clean_text_ML_2'].values)\n",
    "\n",
    "X_tw = tokenizer.texts_to_sequences(df_twitter['clean_text_ML_2'].values)\n",
    "X_tw = pad_sequences(X_tw, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_tw = df_twitter['cyberbullying'].values\n",
    "\n",
    "# Split Data Twitter\n",
    "X_temp_tw, X_test_tw, y_temp_tw, y_test_tw = train_test_split(\n",
    "    X_tw, y_tw, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_tw, X_val_tw, y_train_tw, y_val_tw = train_test_split(\n",
    "    X_temp_tw, y_temp_tw, test_size=1/8, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1d4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# --- Custom F1 Metric ---\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, 'float32'))\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, 'float32'))\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), 'float32'))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-7)\n",
    "    recall = tp / (tp + fn + 1e-7)\n",
    "\n",
    "    return 2 * precision * recall / (precision + recall + 1e-7)\n",
    "\n",
    "# --- Membangun Model Bi-LSTM ---\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy',\n",
    "                 Precision(name=\"precision\"),\n",
    "                 Recall(name=\"recall\"),\n",
    "                 f1_metric\n",
    "                ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2593b6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Training Model pada Data Twitter...\n",
      "Epoch 1/8\n",
      "143/143 [==============================] - 61s 394ms/step - loss: 0.5371 - accuracy: 0.7261 - precision: 0.7784 - recall: 0.4933 - f1_metric: 0.5229 - val_loss: 0.4234 - val_accuracy: 0.7963 - val_precision: 0.8314 - val_recall: 0.6434 - val_f1_metric: 0.7211\n",
      "Epoch 2/8\n",
      "143/143 [==============================] - 49s 343ms/step - loss: 0.3264 - accuracy: 0.8605 - precision: 0.8441 - recall: 0.8222 - f1_metric: 0.8303 - val_loss: 0.3934 - val_accuracy: 0.8263 - val_precision: 0.8232 - val_recall: 0.7445 - val_f1_metric: 0.7789\n",
      "Epoch 3/8\n",
      "143/143 [==============================] - 49s 342ms/step - loss: 0.2609 - accuracy: 0.8929 - precision: 0.8795 - recall: 0.8655 - f1_metric: 0.8706 - val_loss: 0.4114 - val_accuracy: 0.8240 - val_precision: 0.8107 - val_recall: 0.7555 - val_f1_metric: 0.7799\n",
      "Epoch 4/8\n",
      "143/143 [==============================] - 48s 339ms/step - loss: 0.2172 - accuracy: 0.9113 - precision: 0.8954 - recall: 0.8951 - f1_metric: 0.8931 - val_loss: 0.4751 - val_accuracy: 0.8263 - val_precision: 0.7944 - val_recall: 0.7886 - val_f1_metric: 0.7884\n",
      "Epoch 5/8\n",
      "143/143 [==============================] - 65s 454ms/step - loss: 0.1804 - accuracy: 0.9294 - precision: 0.9177 - recall: 0.9151 - f1_metric: 0.9150 - val_loss: 0.4722 - val_accuracy: 0.8186 - val_precision: 0.7770 - val_recall: 0.7941 - val_f1_metric: 0.7827\n",
      "Epoch 6/8\n",
      "143/143 [==============================] - 179s 1s/step - loss: 0.1587 - accuracy: 0.9380 - precision: 0.9270 - recall: 0.9265 - f1_metric: 0.9241 - val_loss: 0.5393 - val_accuracy: 0.8155 - val_precision: 0.8004 - val_recall: 0.7445 - val_f1_metric: 0.7689\n",
      "Epoch 7/8\n",
      "143/143 [==============================] - 138s 964ms/step - loss: 0.1286 - accuracy: 0.9507 - precision: 0.9421 - recall: 0.9413 - f1_metric: 0.9395 - val_loss: 0.6410 - val_accuracy: 0.8140 - val_precision: 0.7961 - val_recall: 0.7463 - val_f1_metric: 0.7669\n",
      "Epoch 8/8\n",
      "143/143 [==============================] - 51s 357ms/step - loss: 0.1118 - accuracy: 0.9574 - precision: 0.9506 - recall: 0.9486 - f1_metric: 0.9478 - val_loss: 0.6245 - val_accuracy: 0.8101 - val_precision: 0.7941 - val_recall: 0.7371 - val_f1_metric: 0.7620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c160d9f00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model pada Twitter\n",
    "model_tw = create_model()\n",
    "print(\"Training Model pada Data Twitter...\")\n",
    "model_tw.fit(\n",
    "    X_train_tw, y_train_tw,\n",
    "    epochs=8,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val_tw, y_val_tw),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d35d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 3s 37ms/step - loss: 0.6188 - accuracy: 0.8017 - precision: 0.7871 - recall: 0.7301 - f1_metric: 0.7534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6188410520553589,\n",
       " 0.8016909956932068,\n",
       " 0.787109375,\n",
       " 0.7300724387168884,\n",
       " 0.7534232139587402]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_tw.evaluate(X_test_tw, y_test_tw, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650e5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bobot model Twitter berhasil disimpan.\n"
     ]
    }
   ],
   "source": [
    "# --- Simpan Weights ---\n",
    "model_tw.save_weights('bilstm_twitter_weights.h5')\n",
    "print(\"Bobot model Twitter berhasil disimpan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8699d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Data YouTube ---\n",
    "df_yt = pd.read_csv('final_data_yt.csv')\n",
    "df_yt = df_yt.dropna(subset=['clean_text_ML_2'])\n",
    "\n",
    "# --- Preprocessing YouTube ---\n",
    "X_yt = tokenizer.texts_to_sequences(df_yt['clean_text_ML_2'].values)\n",
    "X_yt = pad_sequences(X_yt, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "y_yt = df_yt['cyberbullying'].values\n",
    "\n",
    "# Split Data YouTube\n",
    "X_temp_yt, X_test_yt, y_temp_yt, y_test_yt = train_test_split(\n",
    "    X_yt, y_yt, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_yt, X_val_yt, y_train_yt, y_val_yt = train_test_split(\n",
    "    X_temp_yt, y_temp_yt, test_size=1/8, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab24e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.4977548]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load Model & Weights untuk Fine-Tuning ---\n",
    "model_finetune = create_model()\n",
    "\n",
    "# Build model sebelum load weights\n",
    "dummy_input = np.zeros((1, MAX_SEQUENCE_LENGTH))\n",
    "model_finetune(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4b279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bobot Twitter dimuat. Mulai Fine-tuning pada Data YouTube...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load bobot dari Twitter\n",
    "model_finetune.load_weights('bilstm_twitter_weights.h5')\n",
    "print(\"\\nBobot Twitter dimuat. Mulai Fine-tuning pada Data YouTube...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd1fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "8/8 [==============================] - 6s 399ms/step - loss: 1.1951 - accuracy: 0.6176 - precision: 0.5281 - recall: 0.2626 - f1_metric: 0.3061 - val_loss: 0.8352 - val_accuracy: 0.6154 - val_precision: 0.4583 - val_recall: 0.4783 - val_f1_metric: 0.2340\n",
      "Epoch 2/8\n",
      "8/8 [==============================] - 3s 341ms/step - loss: 0.7905 - accuracy: 0.6681 - precision: 0.6000 - recall: 0.4693 - f1_metric: 0.4662 - val_loss: 0.7449 - val_accuracy: 0.6308 - val_precision: 0.4815 - val_recall: 0.5652 - val_f1_metric: 0.2600\n",
      "Epoch 3/8\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.6634 - accuracy: 0.6857 - precision: 0.6139 - recall: 0.5419 - f1_metric: 0.5821 - val_loss: 0.6913 - val_accuracy: 0.6462 - val_precision: 0.5000 - val_recall: 0.5217 - val_f1_metric: 0.2553\n",
      "Epoch 4/8\n",
      "8/8 [==============================] - 3s 332ms/step - loss: 0.5889 - accuracy: 0.7055 - precision: 0.6490 - recall: 0.5475 - f1_metric: 0.6200 - val_loss: 0.6599 - val_accuracy: 0.6923 - val_precision: 0.5714 - val_recall: 0.5217 - val_f1_metric: 0.2727\n",
      "Epoch 5/8\n",
      "8/8 [==============================] - 3s 339ms/step - loss: 0.5458 - accuracy: 0.7341 - precision: 0.7042 - recall: 0.5587 - f1_metric: 0.5896 - val_loss: 0.6429 - val_accuracy: 0.7077 - val_precision: 0.5909 - val_recall: 0.5652 - val_f1_metric: 0.2889\n",
      "Epoch 6/8\n",
      "8/8 [==============================] - 3s 330ms/step - loss: 0.4978 - accuracy: 0.7538 - precision: 0.7248 - recall: 0.6034 - f1_metric: 0.6714 - val_loss: 0.6372 - val_accuracy: 0.6923 - val_precision: 0.5600 - val_recall: 0.6087 - val_f1_metric: 0.2917\n",
      "Epoch 7/8\n",
      "8/8 [==============================] - 3s 350ms/step - loss: 0.4589 - accuracy: 0.7670 - precision: 0.7160 - recall: 0.6760 - f1_metric: 0.7269 - val_loss: 0.6350 - val_accuracy: 0.7077 - val_precision: 0.5769 - val_recall: 0.6522 - val_f1_metric: 0.3061\n",
      "Epoch 8/8\n",
      "8/8 [==============================] - 3s 335ms/step - loss: 0.4270 - accuracy: 0.8022 - precision: 0.7602 - recall: 0.7263 - f1_metric: 0.7411 - val_loss: 0.6294 - val_accuracy: 0.7077 - val_precision: 0.5833 - val_recall: 0.6087 - val_f1_metric: 0.2979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d45ae32b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# --- Fine-Tuning ---\n",
    "model_finetune.fit(\n",
    "    X_train_yt, y_train_yt,\n",
    "    epochs=8,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val_yt, y_val_yt),\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e0afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 38ms/step - loss: 0.6742 - accuracy: 0.6846 - precision: 0.5238 - recall: 0.5116 - f1_metric: 0.4023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6741998791694641,\n",
       " 0.6846153736114502,\n",
       " 0.523809552192688,\n",
       " 0.5116279125213623,\n",
       " 0.4022623896598816]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_finetune.evaluate(X_test_yt, y_test_yt, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
